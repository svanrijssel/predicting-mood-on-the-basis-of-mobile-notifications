{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, cohen_kappa_score, mean_absolute_error, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GaussianNoise\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/Stijn/Documents/Master Data Science and Society/Block 3/thesis/code/thesis_Code/\"\n",
    "mood = pd.read_csv(path+'mood_imputed_median.csv', sep = ',', index_col=0)\n",
    "mood['bored_last'] = mood.groupby('user_id')['bored'].shift()\n",
    "mood.loc[(pd.isnull(mood.bored_last)), 'bored_last'] = mood['bored']\n",
    "mood_bored = mood.drop([\"anxious\", \"content\", \"cheerful\", \"user_id\", \"response_time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize predictors\n",
    "mood_normz = mood_bored.copy()\n",
    "features_to_normalize = ['day_time_window', 'average_TimeUse', 'messaging', 'socialnetworking', 'otherapp']\n",
    "mood_normz[features_to_normalize] = mood_normz[features_to_normalize].apply(lambda x:(x-x.min()) / (x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = predictors, y = target\n",
    "X = mood_normz.iloc[:,1:]\n",
    "y = mood_normz.iloc[:, 0:1]\n",
    "\n",
    "# Convert float to int\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:,:-1]\n",
    "X_onlylastmood = X.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frank & hall encoding\n",
    "\n",
    "def multiple_appends(listname, *element):\n",
    "    listname.extend(element)\n",
    "\n",
    "def ordinal_to_frank(y):\n",
    "    y_trainFH = []\n",
    "    for index, row in y.iterrows():\n",
    "        frankhalltrain = []\n",
    "        if row['bored'] == 0:\n",
    "            multiple_appends(frankhalltrain, 0, 0, 0, 0, 0)\n",
    "        elif row['bored'] == 1:\n",
    "            multiple_appends(frankhalltrain, 1, 0, 0, 0, 0)\n",
    "        elif row['bored'] == 2:\n",
    "            multiple_appends(frankhalltrain, 1, 1, 0, 0, 0)\n",
    "        elif row['bored'] == 3:\n",
    "            multiple_appends(frankhalltrain, 1, 1, 1, 0, 0)\n",
    "        elif row['bored'] == 4:\n",
    "            multiple_appends(frankhalltrain, 1, 1, 1, 1, 0)\n",
    "        elif row['bored'] == 5:\n",
    "            multiple_appends(frankhalltrain, 1, 1, 1, 1, 1)\n",
    "        y_trainFH.append(frankhalltrain)\n",
    "    y_trainFH_df = pd.DataFrame(y_trainFH)\n",
    "    return y_trainFH_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroaverage_mae(test, pred):\n",
    "    mae_0, mae_1, mae_2, mae_3, mae_4, mae_5 = (0,0,0,0,0,0)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        if test[i] == 0 and pred[i] != 0:\n",
    "            mae_0 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 1 and pred[i] != 1:\n",
    "            mae_1 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 2 and pred[i] != 2:\n",
    "            mae_2 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 3 and pred[i] != 3:\n",
    "            mae_3 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 4 and pred[i] != 4:\n",
    "            mae_4 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 5 and pred[i] != 5:\n",
    "            mae_5 += (abs(test[i]-pred[i]))\n",
    "\n",
    "    cnt_0, cnt_1, cnt_2, cnt_3, cnt_4, cnt_5 = (0,0,0,0,0,0)\n",
    "    for z in range(len(test)):\n",
    "        if test[z] == 0:\n",
    "            cnt_0 += 1\n",
    "        if test[z] == 1:\n",
    "            cnt_1 += 1\n",
    "        if test[z] == 2:\n",
    "            cnt_2 += 1\n",
    "        if test[z] == 3:\n",
    "            cnt_3 += 1\n",
    "        if test[z] == 4:\n",
    "            cnt_4 += 1\n",
    "        if test[z] == 5:\n",
    "            cnt_5 += 1\n",
    "\n",
    "    mae_macroaverage = ((mae_0/cnt_0) + (mae_1/cnt_1) + (mae_2/cnt_2) + (mae_3/cnt_3) + (mae_4/cnt_4) + (mae_5/cnt_5)) / 6\n",
    "    return mae_macroaverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fh_pred(pred):\n",
    "    FH_pred = []\n",
    "    for i in pred:\n",
    "        temp_list = []\n",
    "        for binary in i:\n",
    "            if binary >= 0.5:\n",
    "                temp_list.append(1)\n",
    "            else:\n",
    "                temp_list.append(0)\n",
    "        FH_pred.append(temp_list)\n",
    "\n",
    "    FH_prediction = pd.DataFrame(data=FH_pred, columns=['mood_0', 'mood_1', 'mood_2', 'mood_3', 'mood_4'])\n",
    "    real_pred = FH_prediction.sum(axis=1)\n",
    "    return real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fh_test(test):\n",
    "    real_test = test.sum(axis=1)\n",
    "    return real_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "n_split=10\n",
    "f1_scores = []\n",
    "mmae_scores= []\n",
    "f1_scores_classes = []\n",
    "for train_index, test_index in KFold(n_splits = n_split, random_state=2, shuffle=True).split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    sm = SMOTENC(categorical_features=[0, 2], random_state = 2) \n",
    "    X_train_oversampl, y_train_oversampl = sm.fit_sample(X_train, y_train['bored'].ravel())\n",
    "    \n",
    "    y_train_df = pd.DataFrame(y_train_oversampl, columns=['bored'])\n",
    "    y_frank = ordinal_to_frank(y_train_df)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(5, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train_oversampl, y_frank,epochs=100, batch_size=512, verbose=0)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    pred = transform_fh_pred(y_pred).values\n",
    "    test = y_test.values\n",
    "    \n",
    "    f1_scores_classes.append(f1_score(test, pred, average=None))\n",
    "    f1_scores.append(round(f1_score(test, pred, average='weighted'), 4))\n",
    "    mmae_scores.append(macroaverage_mae(test, pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged F1-scores:  [0.0853, 0.1045, 0.0714, 0.087, 0.0783, 0.0925, 0.0883, 0.0773, 0.0908, 0.0893]\n",
      "Mean MA F1-scores:  0.0865\n",
      "Std MA F1-scores:  0.0088\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro-averaged F1-scores: \", f1_scores)\n",
    "print(\"Mean MA F1-scores: \", round(np.mean(f1_scores), 4))\n",
    "print(\"Std MA F1-scores: \", round(np.std(f1_scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged MAE:  [1.4844, 1.4898, 1.4421, 1.5162, 1.5223, 1.4424, 1.4637, 1.4969, 1.5663, 1.5129]\n",
      "Mean MMAE-scores:  1.4937\n",
      "Std MMAE-scores:  0.0364\n"
     ]
    }
   ],
   "source": [
    "mmae_scores_rounded = []\n",
    "for a in mmae_scores:\n",
    "    for b in a:\n",
    "        mmae_scores_rounded.append(round(b, 4))\n",
    "        \n",
    "print(\"Macro-averaged MAE: \", mmae_scores_rounded)\n",
    "print(\"Mean MMAE-scores: \", round(np.mean(mmae_scores), 4))\n",
    "print(\"Std MMAE-scores: \", round(np.std(mmae_scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score per class:  [0.0019, 0.1127, 0.2345, 0.1991, 0.0452, 0.0]\n",
      "STD F1-score per class:  [0.0026, 0.034, 0.0311, 0.0235, 0.0333, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score per class: \", [round(np.mean(x), 4) for x in zip(*f1_scores_classes)])\n",
    "print(\"STD F1-score per class: \", [round(np.std(x), 4) for x in zip(*f1_scores_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
