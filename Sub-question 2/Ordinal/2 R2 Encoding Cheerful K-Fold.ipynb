{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, cohen_kappa_score, mean_absolute_error, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GaussianNoise\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/Stijn/Documents/Master Data Science and Society/Block 3/thesis/code/thesis_Code/\"\n",
    "mood = pd.read_csv(path+'mood_imputed_median.csv', sep = ',', index_col=0)\n",
    "mood_cheerful = mood.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheerfulR2 = []\n",
    "for a in mood['cheerful']:\n",
    "    if a == 0:\n",
    "      cheerfulR2.append(0)  \n",
    "    if a == 1:\n",
    "      cheerfulR2.append(2)\n",
    "    if a == 2:\n",
    "      cheerfulR2.append(3)\n",
    "    if a == 3:\n",
    "      cheerfulR2.append(4)\n",
    "    if a == 4:\n",
    "      cheerfulR2.append(5)\n",
    "    if a == 5:\n",
    "      cheerfulR2.append(7)\n",
    "mood_cheerful['cheerfulR2'] = cheerfulR2\n",
    "mood_cheerful = mood_cheerful.drop(['cheerful'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_cheerful['cheerful_last'] = mood_cheerful.groupby('user_id')['cheerfulR2'].shift()\n",
    "mood_cheerful.loc[(pd.isnull(mood_cheerful.cheerful_last)), 'cheerful_last'] = mood_cheerful['cheerfulR2']\n",
    "mood_cheerful = mood_cheerful.drop([\"content\", \"bored\", \"anxious\", \"user_id\", \"response_time\"], axis=1)\n",
    "mood_cheerful = mood_cheerful[['cheerfulR2', 'day_time_window', 'average_TimeUse', 'bulk', 'messaging', 'socialnetworking', 'otherapp', 'cheerful_last']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize predictors\n",
    "mood_normz = mood_cheerful.copy()\n",
    "features_to_normalize = ['day_time_window', 'average_TimeUse', 'messaging', 'socialnetworking', 'otherapp']\n",
    "mood_normz[features_to_normalize] = mood_normz[features_to_normalize].apply(lambda x:(x-x.min()) / (x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = predictors, y = target\n",
    "X = mood_normz.iloc[:,1:]\n",
    "y = mood_normz.iloc[:, 0:1]\n",
    "\n",
    "# Convert float to int\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:,:-1]\n",
    "X_onlylastmood = X.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroaverage_mae(test, pred):\n",
    "    mae_0, mae_1, mae_2, mae_3, mae_4, mae_5 = (0,0,0,0,0,0)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        if test[i] == 0 and pred[i] != 0:\n",
    "            mae_0 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 2 and pred[i] != 2:\n",
    "            mae_1 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 3 and pred[i] != 3:\n",
    "            mae_2 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 4 and pred[i] != 4:\n",
    "            mae_3 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 5 and pred[i] != 5:\n",
    "            mae_4 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 7 and pred[i] != 7:\n",
    "            mae_5 += (abs(test[i]-pred[i]))\n",
    "\n",
    "    cnt_0, cnt_1, cnt_2, cnt_3, cnt_4, cnt_5 = (0,0,0,0,0,0)\n",
    "    for z in range(len(test)):\n",
    "        if test[z] == 0:\n",
    "            cnt_0 += 1\n",
    "        if test[z] == 2:\n",
    "            cnt_1 += 1\n",
    "        if test[z] == 3:\n",
    "            cnt_2 += 1\n",
    "        if test[z] == 4:\n",
    "            cnt_3 += 1\n",
    "        if test[z] == 5:\n",
    "            cnt_4 += 1\n",
    "        if test[z] == 7:\n",
    "            cnt_5 += 1\n",
    "\n",
    "    mae_macroaverage = ((mae_0/cnt_0) + (mae_1/cnt_1) + (mae_2/cnt_2) + (mae_3/cnt_3) + (mae_4/cnt_4) + (mae_5/cnt_5)) / 6\n",
    "    return mae_macroaverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_R2(pred):   \n",
    "    cat_list = [0,3,4,5,7,9]\n",
    "    transf_pred = []\n",
    "    for a in pred:\n",
    "        for b in a:\n",
    "            d = min(cat_list, key=lambda x:abs(x-b))\n",
    "            transf_pred.append(round(d))\n",
    "    return transf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_time_window</th>\n",
       "      <th>average_TimeUse</th>\n",
       "      <th>bulk</th>\n",
       "      <th>messaging</th>\n",
       "      <th>socialnetworking</th>\n",
       "      <th>otherapp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.025358</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      day_time_window  average_TimeUse  bulk  messaging  socialnetworking  \\\n",
       "4825         0.666667         0.000316     0   0.000000               0.0   \n",
       "4826         1.000000         0.030226     0   0.009524               0.0   \n",
       "245          0.000000         0.009677     0   0.000000               0.0   \n",
       "4827         0.333333         0.000000     0   0.000000               0.0   \n",
       "4828         0.666667         0.025358     0   0.028571               0.0   \n",
       "\n",
       "      otherapp  \n",
       "4825  0.008547  \n",
       "4826  0.017094  \n",
       "245   0.017094  \n",
       "4827  0.000000  \n",
       "4828  0.017094  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Stijn/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "n_split=10\n",
    "f1_scores = []\n",
    "mmae_scores = []\n",
    "f1_scores_classes = []\n",
    "\n",
    "for train_index, test_index in KFold(n_splits = n_split, random_state=2, shuffle=True).split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    sm = SMOTENC(categorical_features=[0, 2], random_state = 2) \n",
    "    X_train_oversampl, y_train_oversampl = sm.fit_sample(X_train, y_train['cheerfulR2'].ravel()) \n",
    "    X_use, y_use = shuffle(X_train_oversampl, y_train_oversampl)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_use, y_use,epochs=100, batch_size=512, verbose=0)\n",
    "    y_pred = model.predict(X_test)\n",
    "    test = y_test.values\n",
    "\n",
    "    pred = nearest_R2(y_pred)\n",
    "\n",
    "    c_test = []\n",
    "    for c in test:\n",
    "        c_test.append(c)\n",
    "    \n",
    "    f1_scores_classes.append(f1_score(c_test, pred, average=None))\n",
    "    f1_scores.append(round(f1_score(c_test, pred, average='weighted'), 4))\n",
    "    mmae_scores.append(macroaverage_mae(c_test, pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score per class:  [0.0, 0.0, 0.311, 0.3531, 0.013, 0.0]\n",
      "STD F1-score per class:  [0.0, 0.0, 0.0305, 0.0323, 0.0168, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score per class: \", [round(np.mean(x), 4) for x in zip(*f1_scores_classes)])\n",
    "print(\"STD F1-score per class: \", [round(np.std(x), 4) for x in zip(*f1_scores_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged F1-scores:  [0.178, 0.1693, 0.1742, 0.1746, 0.1644, 0.1593, 0.1717, 0.1793, 0.169, 0.1745]\n",
      "Mean MA F1-scores:  0.1714\n",
      "Std MA F1-scores:  0.0058\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro-averaged F1-scores: \", f1_scores)\n",
    "print(\"Mean MA F1-scores: \", round(np.mean(f1_scores), 4))\n",
    "print(\"Std MA F1-scores: \", round(np.std(f1_scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged MAE:  [1.804, 1.7894, 1.8097, 1.8131, 1.7807, 1.836, 1.8255, 1.7951, 1.8203, 1.8051]\n",
      "Mean MMAE-scores:  1.8079\n",
      "Std MMAE-scores:  0.016\n"
     ]
    }
   ],
   "source": [
    "mmae_scores_rounded = []\n",
    "for a in mmae_scores:\n",
    "    for b in a:\n",
    "        mmae_scores_rounded.append(round(b, 4))\n",
    "        \n",
    "print(\"Macro-averaged MAE: \", mmae_scores_rounded)\n",
    "print(\"Mean MMAE-scores: \", round(np.mean(mmae_scores), 4))\n",
    "print(\"Std MMAE-scores: \", round(np.std(mmae_scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
