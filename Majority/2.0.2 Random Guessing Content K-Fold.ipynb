{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, cohen_kappa_score, mean_absolute_error, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GaussianNoise\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/Stijn/Documents/Master Data Science and Society/Block 3/thesis/code/thesis_Code/\"\n",
    "mood = pd.read_csv(path+'mood_imputed_median.csv', sep = ',', index_col=0)\n",
    "mood['content_last'] = mood.groupby('user_id')['content'].shift()\n",
    "mood.loc[(pd.isnull(mood.content_last)), 'content_last'] = mood['content']\n",
    "mood_content = mood.drop([\"bored\", \"anxious\", \"cheerful\", \"user_id\", \"response_time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize predictors\n",
    "mood_normz = mood_content.copy()\n",
    "features_to_normalize = ['day_time_window', 'average_TimeUse', 'messaging', 'socialnetworking', 'otherapp']\n",
    "mood_normz[features_to_normalize] = mood_normz[features_to_normalize].apply(lambda x:(x-x.min()) / (x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = predictors, y = target\n",
    "X = mood_normz.iloc[:,1:]\n",
    "y = mood_normz.iloc[:, 0:1]\n",
    "\n",
    "# Convert float to int\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:,:-1]\n",
    "X_onlylastmood = X.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3972\n",
       "4    2958\n",
       "2    2775\n",
       "1    1559\n",
       "0    1090\n",
       "5     867\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroaverage_mae(test, pred):\n",
    "    mae_0, mae_1, mae_2, mae_3, mae_4, mae_5 = (0,0,0,0,0,0)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        if test[i] == 0 and pred[i] != 0:\n",
    "            mae_0 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 1 and pred[i] != 1:\n",
    "            mae_1 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 2 and pred[i] != 2:\n",
    "            mae_2 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 3 and pred[i] != 3:\n",
    "            mae_3 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 4 and pred[i] != 4:\n",
    "            mae_4 += (abs(test[i]-pred[i]))\n",
    "        if test[i] == 5 and pred[i] != 5:\n",
    "            mae_5 += (abs(test[i]-pred[i]))\n",
    "\n",
    "    cnt_0, cnt_1, cnt_2, cnt_3, cnt_4, cnt_5 = (0,0,0,0,0,0)\n",
    "    for z in range(len(test)):\n",
    "        if test[z] == 0:\n",
    "            cnt_0 += 1\n",
    "        if test[z] == 1:\n",
    "            cnt_1 += 1\n",
    "        if test[z] == 2:\n",
    "            cnt_2 += 1\n",
    "        if test[z] == 3:\n",
    "            cnt_3 += 1\n",
    "        if test[z] == 4:\n",
    "            cnt_4 += 1\n",
    "        if test[z] == 5:\n",
    "            cnt_5 += 1\n",
    "\n",
    "    mae_macroaverage = ((mae_0/cnt_0) + (mae_1/cnt_1) + (mae_2/cnt_2) + (mae_3/cnt_3) + (mae_4/cnt_4) + (mae_5/cnt_5)) / 6\n",
    "    return mae_macroaverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3004311322895394\n",
      "0.22373496709779894\n",
      "0.20989335148627183\n",
      "0.11791846305120642\n",
      "0.082444595718932\n",
      "0.06557749035625142\n"
     ]
    }
   ],
   "source": [
    "print(3972/13221)\n",
    "print(2958/13221)\n",
    "print(2775/13221)\n",
    "print(1559/13221)\n",
    "print(1090/13221)\n",
    "print(867/13221)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split=10\n",
    "f1_scores = []\n",
    "mmae_scores = []\n",
    "f1_scores_classes = []\n",
    "for train_index, test_index in KFold(n_splits = n_split, random_state=2, shuffle=True).split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    pred = []\n",
    "    for a in range(len(y_test)):\n",
    "        pred.append(np.random.choice(np.arange(0, 6), p=[0.3004, 0.2237, 0.2099, 0.1180, 0.0824, 0.0656]))\n",
    "    test = y_test.values\n",
    "    \n",
    "    f1_scores_classes.append(f1_score(test, pred, average=None))\n",
    "    f1_scores.append(round(f1_score(test, pred, average='weighted'), 4))\n",
    "    mmae_scores.append(macroaverage_mae(test, pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged F1-scores:  [0.1604, 0.1738, 0.1751, 0.1374, 0.158, 0.1482, 0.1477, 0.1758, 0.149, 0.1671]\n",
      "Mean MA F1-scores:  0.1593\n",
      "Std MA F1-scores:  0.0128\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro-averaged F1-scores: \", f1_scores)\n",
    "print(\"Mean MA F1-scores: \", round(np.mean(f1_scores), 4))\n",
    "print(\"Std MA F1-scores: \", round(np.std(f1_scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-averaged MAE:  [1.9301, 1.9931, 1.8836, 2.0544, 1.9715, 1.9394, 1.955, 1.9076, 1.9704, 2.0196]\n",
      "Mean MMAE-scores:  1.9625\n",
      "Std MMAE-scores:  0.0487\n"
     ]
    }
   ],
   "source": [
    "mmae_scores_rounded = []\n",
    "for a in mmae_scores:\n",
    "    for b in a:\n",
    "        mmae_scores_rounded.append(round(b, 4))\n",
    "        \n",
    "print(\"Macro-averaged MAE: \", mmae_scores_rounded)\n",
    "print(\"Mean MMAE-scores: \", round(np.mean(mmae_scores), 4))\n",
    "print(\"Std MMAE-scores: \", round(np.std(mmae_scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1-score per class:  [0.1377, 0.1517, 0.2192, 0.1697, 0.1301, 0.0603]\n",
      "STD F1-score per class:  [0.0186, 0.01, 0.0271, 0.0306, 0.0129, 0.0136]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1-score per class: \", [round(np.mean(x), 4) for x in zip(*f1_scores_classes)])\n",
    "print(\"STD F1-score per class: \", [round(np.std(x), 4) for x in zip(*f1_scores_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
